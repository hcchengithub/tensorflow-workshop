{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4huUGkHaATV4"
   },
   "source": [
    "Pre-Download Data\n",
    "===\n",
    "\n",
    "To save you the hassle of repeated downloads, it's easier so save the files in a shared folder.\n",
    "\n",
    "To run all cells, select **Cell** > **Run All**. You can also run cells one at a time, select **Cell** > **Run cells** in the menu above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "Pq6AyJUJATV7",
    "outputId": "27d1c78f-3957-4211-a011-94984c541616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: frog\n",
      "Class 1: horse\n",
      "Class 2: lion\n",
      "Class 3: monkey\n",
      "Class 4: octopus\n",
      "Class 5: owl\n",
      "Class 6: rhinoceros\n",
      "Class 7: snail\n",
      "Class 8: tiger\n",
      "Class 9: zebra\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Some of these are hard to distinguish.\n",
    "# Check https://quickdraw.withgoogle.com/data for examples\n",
    "zoo = ['frog', 'horse', 'lion', 'monkey', 'octopus', 'owl', 'rhinoceros', \n",
    "       'snail', 'tiger', 'zebra']\n",
    "\n",
    "# Mapping between category names and ids\n",
    "animal2id = dict((c,i) for i,c in enumerate(zoo))\n",
    "id2animal = dict((i,c) for i,c in enumerate(zoo))\n",
    "for i, animal in id2animal.items():\n",
    "    print(\"Class {}: {}\".format(i, animal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for animal in zoo:\n",
    "    url = \"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{}.npy\".format(animal)\n",
    "    print(url + \" --> \" + DATA_DIR)\n",
    "\n",
    "'''\n",
    "下一 cell 的 data download 太慢了，再加上翻牆 maybe_download(url, DATA_DIR) 慢得受不了，改用 wget 有效\n",
    "\n",
    "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frog.npy --> data/\n",
    "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/horse.npy --> data/\n",
    "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lion.npy --> data/\n",
    "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/monkey.npy --> data/\n",
    "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/octopus.npy --> data/\n",
    "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/owl.npy --> data/\n",
    "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rhinoceros.npy --> data/\n",
    "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snail.npy --> data/\n",
    "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tiger.npy --> data/\n",
    "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/zebra.npy --> data/\n",
    "\n",
    "--- 1.bat ---\n",
    "    :frog\n",
    "    wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frog.npy\n",
    "    dir frog.npy\n",
    "    if errorlevel 1 goto frog\n",
    "    :horse\n",
    "    wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/horse.npy\n",
    "    dir horse.npy\n",
    "    if errorlevel 1 goto horse\n",
    "    :lion\n",
    "    wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lion.npy\n",
    "    dir lion.npy\n",
    "    if errorlevel 1 goto lion\n",
    "    :monkey\n",
    "    wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/monkey.npy\n",
    "    dir monkey.npy\n",
    "    if errorlevel 1 goto monkey\n",
    "    :octopus\n",
    "    wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/octopus.npy\n",
    "    dir octopus.npy\n",
    "    if errorlevel 1 goto octopus\n",
    "    :owl\n",
    "    wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/owl.npy\n",
    "    dir owl.npy\n",
    "    if errorlevel 1 goto owl\n",
    "    :rhinoceros\n",
    "    wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rhinoceros.npy\n",
    "    dir rhinoceros.npy\n",
    "    if errorlevel 1 goto rhinoceros\n",
    "    :snail\n",
    "    wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snail.npy\n",
    "    dir snail.npy\n",
    "    if errorlevel 1 goto snail\n",
    "    :tiger\n",
    "    wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tiger.npy\n",
    "    dir tiger.npy\n",
    "    if errorlevel 1 goto tiger\n",
    "    :zebra\n",
    "    wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/zebra.npy\n",
    "    dir zebra.npy\n",
    "    if errorlevel 1 goto zebra\n",
    "--- 1.bat ---\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load in module numpy.lib.npyio:\n",
      "\n",
      "load(file, mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')\n",
      "    Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    file : file-like object, string, or pathlib.Path\n",
      "        The file to read. File-like objects must support the\n",
      "        ``seek()`` and ``read()`` methods. Pickled files require that the\n",
      "        file-like object support the ``readline()`` method as well.\n",
      "    mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional\n",
      "        If not None, then memory-map the file, using the given mode (see\n",
      "        `numpy.memmap` for a detailed description of the modes).  A\n",
      "        memory-mapped array is kept on disk. However, it can be accessed\n",
      "        and sliced like any ndarray.  Memory mapping is especially useful\n",
      "        for accessing small fragments of large files without reading the\n",
      "        entire file into memory.\n",
      "    allow_pickle : bool, optional\n",
      "        Allow loading pickled object arrays stored in npy files. Reasons for\n",
      "        disallowing pickles include security, as loading pickled data can\n",
      "        execute arbitrary code. If pickles are disallowed, loading object\n",
      "        arrays will fail.\n",
      "        Default: True\n",
      "    fix_imports : bool, optional\n",
      "        Only useful when loading Python 2 generated pickled files on Python 3,\n",
      "        which includes npy/npz files containing object arrays. If `fix_imports`\n",
      "        is True, pickle will try to map the old Python 2 names to the new names\n",
      "        used in Python 3.\n",
      "    encoding : str, optional\n",
      "        What encoding to use when reading Python 2 strings. Only useful when\n",
      "        loading Python 2 generated pickled files on Python 3, which includes\n",
      "        npy/npz files containing object arrays. Values other than 'latin1',\n",
      "        'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n",
      "        data. Default: 'ASCII'\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    result : array, tuple, dict, etc.\n",
      "        Data stored in the file. For ``.npz`` files, the returned instance\n",
      "        of NpzFile class must be closed to avoid leaking file descriptors.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    IOError\n",
      "        If the input file does not exist or cannot be read.\n",
      "    ValueError\n",
      "        The file contains an object array, but allow_pickle=False given.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    save, savez, savez_compressed, loadtxt\n",
      "    memmap : Create a memory-map to an array stored in a file on disk.\n",
      "    lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    - If the file contains pickle data, then whatever object is stored\n",
      "      in the pickle is returned.\n",
      "    - If the file is a ``.npy`` file, then a single array is returned.\n",
      "    - If the file is a ``.npz`` file, then a dictionary-like object is\n",
      "      returned, containing ``{filename: array}`` key-value pairs, one for\n",
      "      each file in the archive.\n",
      "    - If the file is a ``.npz`` file, the returned value supports the\n",
      "      context manager protocol in a similar fashion to the open function::\n",
      "    \n",
      "        with load('foo.npz') as data:\n",
      "            a = data['a']\n",
      "    \n",
      "      The underlying file descriptor is closed when exiting the 'with'\n",
      "      block.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Store data to disk, and load it again:\n",
      "    \n",
      "    >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n",
      "    >>> np.load('/tmp/123.npy')\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "    \n",
      "    Store compressed data to disk, and load it again:\n",
      "    \n",
      "    >>> a=np.array([[1, 2, 3], [4, 5, 6]])\n",
      "    >>> b=np.array([1, 2])\n",
      "    >>> np.savez('/tmp/123.npz', a=a, b=b)\n",
      "    >>> data = np.load('/tmp/123.npz')\n",
      "    >>> data['a']\n",
      "    array([[1, 2, 3],\n",
      "           [4, 5, 6]])\n",
      "    >>> data['b']\n",
      "    array([1, 2])\n",
      "    >>> data.close()\n",
      "    \n",
      "    Mem-map the stored array, and then access the second row\n",
      "    directly from disk:\n",
      "    \n",
      "    >>> X = np.load('/tmp/123.npy', mmap_mode='r')\n",
      "    >>> X[1, :]\n",
      "    memmap([4, 5, 6])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "1VQp7YCUATWH",
    "outputId": "c7236449-681f-419a-91eb-714e8f5fa719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using previously downloaded file: data/frog.npy\n",
      "Loaded 1000 frog examples of dimension 784 from data/frog.npy\n",
      "Using previously downloaded file: data/horse.npy\n",
      "Loaded 1000 horse examples of dimension 784 from data/horse.npy\n",
      "Using previously downloaded file: data/lion.npy\n",
      "Loaded 1000 lion examples of dimension 784 from data/lion.npy\n",
      "Using previously downloaded file: data/monkey.npy\n",
      "Loaded 1000 monkey examples of dimension 784 from data/monkey.npy\n",
      "Using previously downloaded file: data/octopus.npy\n",
      "Loaded 1000 octopus examples of dimension 784 from data/octopus.npy\n",
      "Using previously downloaded file: data/owl.npy\n",
      "Loaded 1000 owl examples of dimension 784 from data/owl.npy\n",
      "Using previously downloaded file: data/rhinoceros.npy\n",
      "Loaded 1000 rhinoceros examples of dimension 784 from data/rhinoceros.npy\n",
      "Using previously downloaded file: data/snail.npy\n",
      "Loaded 1000 snail examples of dimension 784 from data/snail.npy\n",
      "Using previously downloaded file: data/tiger.npy\n",
      "Loaded 1000 tiger examples of dimension 784 from data/tiger.npy\n",
      "Using previously downloaded file: data/zebra.npy\n",
      "Loaded 1000 zebra examples of dimension 784 from data/zebra.npy\n",
      "Final shape of data: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "from six.moves.urllib.request import urlretrieve\n",
    "import os\n",
    "\n",
    "DATA_DIR = 'data/'\n",
    "\n",
    "def maybe_download(url, data_dir):\n",
    "    filename = url.split('/')[-1]\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "\n",
    "    # Check if the file already exists.\n",
    "    if not os.path.exists(file_path):\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)\n",
    "\n",
    "        print(\"Downloading {} to {}\".format(url, file_path))\n",
    "        file_path, _ = urlretrieve(url=url, filename=file_path)\n",
    "    else:\n",
    "        print(\"Using previously downloaded file: {}\".format(file_path))\n",
    "    return file_path\n",
    "\n",
    "def load_data(file_path, max_examples=2000, example_name=''):\n",
    "    d = np.load(open(file_path, 'rb'))  # was 'r' that's wrong hcchen5600-2018-3-6-18:47\n",
    "    d = d[:max_examples,:] # limit number of instances to save memory\n",
    "    print(\"Loaded {} {} examples of dimension {} from {}\".format(\n",
    "            d.shape[0], example_name, d.shape[1], file_path))\n",
    "    return d\n",
    "\n",
    "data= []\n",
    "labels =[]\n",
    "\n",
    "for animal in zoo:\n",
    "    url = \"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{}.npy\".format(animal)\n",
    "    file_path = maybe_download(url, DATA_DIR)\n",
    "    data.append(load_data(file_path, max_examples = 1000, example_name = animal))\n",
    "    labels.extend([animal2id[animal]]*data[-1].shape[0])\n",
    "\n",
    "data = np.concatenate(data, axis=0)\n",
    "labels = np.array(labels)\n",
    "print(\"Final shape of data: {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TrTzMTUzATWO"
   },
   "source": [
    "The data is fun to look at. Compared to MNIST the classes seem much harder to distinguish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {},
      {}
     ]
    },
    "colab_type": "code",
    "id": "qBT_cOQqATWQ",
    "outputId": "9f1fc1d3-d441-4665-ea60-48c7d3fa234b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_samples = 10\n",
    "random_indices = np.random.permutation(data.shape[0])\n",
    "\n",
    "for i in random_indices[:n_samples]:\n",
    "    print(i, labels[i])\n",
    "    print(\"Category {}: {}\".format(labels[i], id2animal[labels[i]]))\n",
    "\n",
    "    # We'll show the image and its pixel value histogram side-by-side.\n",
    "\n",
    "    # To interpret the values as a 28x28 image, we need to reshape\n",
    "    # the numpy array, which is one dimensional.\n",
    "    image = data[i, :]\n",
    "\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.imshow(image.reshape(28, 28), cmap=plt.cm.Greys, interpolation='nearest')\n",
    "    ax2.hist(image, bins=20)\n",
    "    ax1.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "f6nWk5m_ATWW"
   },
   "outputs": [],
   "source": [
    "if data.dtype == 'uint8':  # avoid doing this twice\n",
    "    data = data.astype(np.float32)\n",
    "    data = (data - (255 / 2.0)) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTWItjxEATWZ"
   },
   "source": [
    "Our labels are 0,1,2,..,10 right now. We convert to a one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "ppNaheD2ATWb",
    "outputId": "8ca82368-ebca-4b36-a055-81ed836fd9db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_indices = np.random.permutation(labels.shape[0])\n",
    "\n",
    "print(\"Labels before:\")\n",
    "print(labels[random_indices[:5]])\n",
    "\n",
    "def one_hot(labels, n_classes):\n",
    "    n_labels = len(labels)\n",
    "    one_hot_labels = np.zeros((n_labels, n_classes))\n",
    "    one_hot_labels[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_labels\n",
    "\n",
    "labels_one_hot = one_hot(labels, len(zoo))\n",
    "\n",
    "print(\"Labels after:\")\n",
    "print(labels_one_hot[random_indices[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PLlPgGESATWf"
   },
   "source": [
    "Finally, let's split the data into random train and test partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "-eJjdKcMATWg",
    "outputId": "d212efe4-0d16-48b3-f5fe-043b3bd33a1f"
   },
   "outputs": [],
   "source": [
    "n_test_examples = 1000\n",
    "\n",
    "random_indices = np.random.permutation(data.shape[0])\n",
    "test_data = data[random_indices[:n_test_examples],:]\n",
    "test_labels = labels_one_hot[random_indices[:n_test_examples],:]\n",
    "train_data = data[random_indices[n_test_examples:],:]\n",
    "train_labels = labels_one_hot[random_indices[n_test_examples:],:]\n",
    "print(\"Data shapes: \", test_data.shape, test_labels.shape, train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gBBdknfATWl"
   },
   "source": [
    "Save data for other experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "zH4MNOzMATWn",
    "outputId": "63f3b23f-5aa7-46c0-846f-11c5cb6eff72"
   },
   "outputs": [],
   "source": [
    "outfile_name = os.path.join(DATA_DIR, \"zoo.npz\")\n",
    "with open(outfile_name, 'w') as outfile:\n",
    "    np.savez(outfile, train_data, train_labels, test_data, test_labels)\n",
    "print (\"Saved train/test data to {}\".format(outfile_name))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "0_Download_Data.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
